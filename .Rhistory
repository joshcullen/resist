proj4string(dist2rdN_30m) == proj4string(dat.N_sp)
crs(dat.N_sp)
crs(dat.N_sp)<- crs(dist2rdN_30m)
crs(dat.N_sp)
identical(crs(dat.N_sp), crs(dist2rdN_30m))
View(dat.N_sp)
path_N<- raster::extract(dist2rdN_30m, dat.N_sp, along = TRUE, cellnumbers = TRUE)
View(path_N)
unique(dat.N$id)
names(path_N)<- unique(dat.N$id)
View(path_N)
path_N_df = purrr::map_dfr(path_N, as_data_frame, .id = "id")
View(path_N_df)
names(path_N_df)[3]<- "dist2rd"
path_N_coords = xyFromCell(dist2rdN_30m, path_N_df$cell)
#double-check that extracted grid cells overlap with tm14 path
bar<- dist2rdN_30m
bar[]<- NA
bar[path_N_df$cell]<- dist2rdN_30m[path_N_df$cell]
plot(bar)
plot(st_geometry(dat.N_sf), add=T)
#Label all observations with cell number and time interval
dat.N$cell<- cellFromXY(dist2rdN_30m, dat.N[,c("x","y")])
cellFromXY(dist2rdN_30m, dat.N[,c("x","y")])
View(dat.N)
str(dat.N)
class(dist2rdN_30m)
dat.N[,c("x","y")]
dat<- read.csv("three_banded_over20_for_Josh.csv", header = T, sep = ",")
dat$id<- as.character(dat$id)
dat$date<- as.POSIXct(strptime(dat$date, format = "%d/%m/%Y %H:%M"))
coords<- dat[c("x","y")]
dat.spdf<- SpatialPointsDataFrame(coords = coords, data = dat)
proj4string(dat.spdf)<- CRS("+init=epsg:32721")
proj4string(dat.spdf)
dat.N<- dat[dat$y > 8100000,]
dat.S<- dat[dat$y < 8100000,]
### Read in rasters
setwd("~/Documents/Snail Kite Project/Data/armadillos/Environ Data")
rast<- dir(getwd(), "*.tif$")
for (i in rast) assign(i, raster(i))
EucDist_cerc_Copy.tif
#Need to project rasters same as tracks
EucDist_cerc_Copy.tif<- projectRaster(EucDist_cerc_Copy.tif, crs = "+init=epsg:32721")
EucDist_cerc_Copy.tif
crs(EucDist_cercaAm.tif)
crs(EucDist_cercaAm.tif)<- crs(EucDist_cerc_Copy.tif)
crs(EucDist_cercaAm.tif)
dat.N<- subset(dat.spdf, dat.spdf$y > 8100000)
dat.S<- subset(dat.spdf, dat.spdf$y < 8100000)
View(dat.N)
plot(dat.N)
plot(dat.S)
crs(dat.N)
dat.N_sf<- st_as_sf(dat.N)
View(dat.N_sf)
dat.N_sf<- st_sf(dat.N)
dat.N_sf<- st_as_sf(dat.N)
crs(dat.N_sf)
# Convert DFs to linestrings by ID
dat.N_sf<- st_as_sf(dat.N) %>%
group_by(id) %>%
summarize(do_union = FALSE) %>%
st_cast("LINESTRING")
View(dat.N_sf)
plot(dat.N_sf)
projectExtent(dat.N_sf)
projection(dat.N_sf)
# Convert DFs to linestrings by ID
dat.N_sf<- st_as_sf(dat.N) %>%
group_by(id) %>%
summarize(do_union = FALSE) %>%
st_cast("LINESTRING") %>%
as_Spatial()
plot(dat.N_sf)
projection(dat.N_sf)
foo<- as.SpatialLines.SLDF(dat.N)
dat.N$id
#Convert to Spatial Lines Data Frame
x <- lapply(split(dat.N, dat.N$id), function(x) Lines(list(Line(coordinates(x))), dat.N$id[1L]))
View(x)
# the corrected part goes here:
lines <- SpatialLines(x)
x$tm14
#Convert to Spatial Lines Data Frame
x <- lapply(split(dat.N, dat.N$id), function(x) Lines(list(Line(coordinates(x))), x$id[1L]))
# the corrected part goes here:
lines <- SpatialLines(x)
data <- data.frame(id = unique(dat.N$id))
rownames(data) <- data$id
l <- SpatialLinesDataFrame(lines, data)
plot(l)
crs(l)
crs(l)<- CRS("+init=epsg:32721")
crs(l)
dat.N_sldf <- SpatialLinesDataFrame(lines, data)
crs(dat.N_sldf)<- CRS("+init=epsg:32721")
## Aggregate spatial data to same scale (which will likely be 30m)
res(EucDist_cerc_Copy.tif) #13m 13m
dist2rdN_30m<- raster::aggregate(EucDist_cerc_Copy.tif,
fact = 2,
fun = mean)
#N
# dat.N_sp<- as(dat.N_sf, "Spatial")
# crs(dat.N_sp)<- crs(dist2rdN_30m)
path_N<- raster::extract(dist2rdN_30m, dat.N_sldf, along = TRUE, cellnumbers = TRUE)
names(path_N)
View(lines)
View(path_N)
unique(dat.N$id)
dat.N$id
names(path_N)<- unique(dat.N$id)
path_N_df = purrr::map_dfr(path_N, as_data_frame, .id = "id")
names(path_N_df)[3]<- "dist2rd"
View(path_N_df)
path_N_coords = xyFromCell(dist2rdN_30m, path_N_df$cell)
#double-check that extracted grid cells overlap with tm14 path
bar<- dist2rdN_30m
bar[]<- NA
bar[path_N_df$cell]<- dist2rdN_30m[path_N_df$cell]
plot(bar)
# plot(st_geometry(dat.N_sf), add=T)
plot(dat.N_sldf, add=T)
#Label all observations with cell number and time interval
dat.N$cell<- cellFromXY(dist2rdN_30m, dat.N[,c("x","y")])
View(dat.N)
dat.N@data<- dat.N@data %>%
group_by(id) %>%
mutate(dt = difftime(date, lag(date), units = "sec")) %>%
ungroup()
View(dat.N)
j=1
path_df<- path_N_df
track_df<- dat.N@data
id
id="id"
path.list<- df.to.list(dat = path_df, ind = id)
df.to.list = function(dat, ind) {  #ind must be in quotes
id<- unique(dat[,ind]) %>% dplyr::pull()
n=length(id)
dat.list<- vector("list", n)
names(dat.list)<- id
for (i in 1:length(id)) {
tmp<- which(dat[,ind] == id[i])
dat.list[[i]]<- dat[tmp,]
}
dat.list
}
path.list<- df.to.list(dat = path_df, ind = id)
track.list<- df.to.list(dat = track_df, ind = id)
ind<- vector()
for (i in 2:nrow(path.list[[j]])) {
if (path.list[[j]]$cell[i] == path.list[[j]]$cell[i-1])
ind<- c(ind, (i-1))
}
ind<- c(1, ind, nrow(path.list[[j]]))
track.list[[j]]$time1<- ind
j=2
ind<- vector()
for (i in 2:nrow(path.list[[j]])) {
if (path.list[[j]]$cell[i] == path.list[[j]]$cell[i-1])
ind<- c(ind, (i-1))
}
View(track.list)
j=1
ind<- vector()
for (i in 2:(nrow(path.list[[j]]) - 1)) {
if (path.list[[j]]$cell[i] == path.list[[j]]$cell[i+1])
ind<- c(ind, i)
}
ind<- c(1, ind, nrow(path.list[[j]]))
j=2
ind<- vector()
for (i in 2:(nrow(path.list[[j]]) - 1)) {
if (path.list[[j]]$cell[i] == path.list[[j]]$cell[i+1])
ind<- c(ind, i)
}
ind<- c(1, ind, nrow(path.list[[j]]))
View(path.list)
View(path.list[["tm30"]])
View(path.list[["tm30"]])
library('Rcpp')
set.seed(1)
source('gibbs_resist.R')
source('gibbs_resist_func.R')
sourceCpp('resist_aux.cpp')
dat<- read.csv("fake data.csv")
View(dat)
ind=grep('covs',colnames(dat))
xmat=data.matrix(cbind(1,dat[,ind]))
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','ysoma')])
View(tmp)
cond=!is.na(tmp$ysoma)
ysoma=tmp[cond,'ysoma']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
library(tidyverse)
library(sf)
library(raster)
library(lubridate)
library(sp)
source('helper functions.R')
library(tidyverse)
library(sf)
library(raster)
library(lubridate)
library(sp)
source('helper functions.R')
setwd("~/Documents/Snail Kite Project/Data/armadillos")
dat<- read.csv("three_banded_over20_for_Josh.csv", header = T, sep = ",")
dat$id<- as.character(dat$id)
dat$date<- as.POSIXct(strptime(dat$date, format = "%d/%m/%Y %H:%M"))
dat.N<- dat[dat$y > 8100000,]
dat.S<- dat[dat$y < 8100000,]
### Read in rasters
setwd("~/Documents/Snail Kite Project/Data/armadillos/Environ Data")
rast<- dir(getwd(), "*.tif$")
for (i in rast) assign(i, raster(i))
plot(EucDist_cerc_Copy.tif); points(dat.N$x, dat.N$y)
#Need to project rasters same as tracks
EucDist_cerc_Copy.tif<- projectRaster(EucDist_cerc_Copy.tif, crs = "+init=epsg:32721")
## Aggregate spatial data to same scale (which will likely be 30m)
res(EucDist_cerc_Copy.tif) #13m 13m
dist2rdN_30m<- raster::aggregate(EucDist_cerc_Copy.tif,
fact = 2,
fun = mean)
path.N<- extract.covars(dat.N, dist2rdN_30m, crs = "+init=epsg:32721")
# dat.N_sp<- as(dat.N_sf, "Spatial")
# crs(dat.N_sp)<- crs(dist2rdN_30m)
# path_N<- raster::extract(dist2rdN_30m, dat.N_sldf, along = TRUE, cellnumbers = TRUE)
# names(path_N)<- unique(dat.N$id)
# path_N_df = purrr::map_dfr(path_N, as_data_frame, .id = "id")
names(path.N)[3]<- "dist2rd"
View(path.N)
# Export data
setwd("~/Documents/Snail Kite Project/Data/R Scripts/ValleLabUF/resist")
str(path.N)
write.csv(path.N, "Armadillo Resistance Data.csv", row.names = F)
library('Rcpp')
set.seed(1)
source('gibbs_resist.R')
source('gibbs_resist_func.R')
sourceCpp('resist_aux.cpp')
dat=read.csv('Armadillo Resistance Data.csv',as.is=T)
ind=grep('dist2rd',colnames(dat))
xmat=data.matrix(cbind(1,dat[,ind]))
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','dist2rd')])
cond=!is.na(tmp$dist2rd)
ysoma=tmp[cond,'dist2rd']
View(tmp)
#get y soma
tmp=unique(dat[,c('seg.id','dt')])
cond=!is.na(tmp$dt)
ysoma=tmp[cond,'dt']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
View(xmat)
summary(xmat)
summary(seg.id)
var.betas
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
library('Rcpp')
set.seed(1)
source('gibbs_resist.R')
source('gibbs_resist_func.R')
sourceCpp('resist_aux.cpp')
dat=read.csv('Armadillo Resistance Data.csv',as.is=T)
ind=grep('dist',colnames(dat))
xmat=data.matrix(cbind(1,dat[,ind]))
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','dt')])
cond=!is.na(tmp$dt)
ysoma=tmp[cond,'dt']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
View(dat)
dat$veg<- rnorm(nrow(dat), 0, 1)
xmat=data.matrix(cbind(1,dat[,c(3,6)]))
View(xmat)
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
library('Rcpp')
set.seed(1)
source('gibbs_resist.R')
source('gibbs_resist_func.R')
sourceCpp('resist_aux.cpp')
dat=read.csv('Armadillo Resistance Data.csv',as.is=T)
dat$veg<- rnorm(nrow(dat), 0, 1)
xmat=data.matrix(cbind(1,dat[,c(3,6)]))
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','dt')])
cond=!is.na(tmp$dt)
ysoma=tmp[cond,'dt']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
dat<- read.csv("fake data.csv")
View(dat)
ind=1
xmat=data.matrix(cbind(1,dat[,ind]))
dim(xmat)
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','ysoma')])
View(tmp)
cond=!is.na(tmp$ysoma)
ysoma=tmp[cond,'ysoma']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
library('Rcpp')
set.seed(1)
source('gibbs_resist.R')
source('gibbs_resist_func.R')
sourceCpp('resist_aux.cpp')
dat=read.csv('Armadillo Resistance Data.csv',as.is=T)
ind=grep('dist',colnames(dat))
xmat=data.matrix(cbind(1,dat[,ind]))
seg.id=dat$seg.id
ngroup=10
#get y soma
tmp=unique(dat[,c('seg.id','dt')])
cond=!is.na(tmp$dt)
ysoma=tmp[cond,'dt']
ngibbs=10000
nburn=ngibbs/2
#priors
gamma1=0.1
var.betas=c(100,rep(1,ncol(xmat)-1))
n=nrow(xmat)
nparam=ncol(xmat)
nagg=length(ysoma)
#initial parameters
betas=matrix(0,nparam,ngroup)
b.gamma=2
z=sample(1:ngroup,size=nagg,replace=T)
theta=rep(1/ngroup,ngroup)
#stuff for gibbs sampler
jump1=list(betas=matrix(0.1,nparam,ngroup),b.gamma=0.1)
accept1=list(betas=matrix(0,nparam,ngroup),b.gamma=0)
store.betas=matrix(NA,ngibbs,nparam*ngroup)
store.b=matrix(NA,ngibbs,1)
store.theta=matrix(NA,ngibbs,ngroup)
store.llk=matrix(NA,ngibbs,1)
accept.output=50
for (i in 1:ngibbs){
print(i)
#sample betas
tmp=sample.betas(betas=betas,xmat=xmat,ysoma=ysoma,jump=jump1$betas,
b.gamma=b.gamma,nparam=nparam,var.betas=var.betas,
seg.id=seg.id,ngroup=ngroup,nagg=nagg,z=z)
betas=tmp$betas
accept1$betas=accept1$betas+tmp$accept
#sample b.gamma
tmp=sample.b.gamma(betas=betas,xmat=xmat,ysoma=ysoma,jump=jump1$b.gamma,
b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg,z=z)
b.gamma=tmp$b.gamma
accept1$b.gamma=accept1$b.gamma+tmp$accept
# b.gamma=b.true
#sample z
z=sample.z(betas=betas,xmat=xmat,ysoma=ysoma,b.gamma=b.gamma,
seg.id=seg.id,ngroup=ngroup,nagg=nagg,theta=theta)
#sample theta
theta=sample.theta(z=z,gamma1=gamma1,ngroup=ngroup)
#get llk
p=get.llk(betas=betas,xmat=xmat,ysoma=ysoma,b.gamma=b.gamma,
seg.id=seg.id,ngroup=ngroup,nagg=nagg)
#sum the loglikel for the correct group
llk1=GetSomaLlkGroups(llk=p, z=z-1, ngroups=ngroup)
# llk=0
# for (j in 1:ngroup){
#   cond=z==j
#   llk=llk+sum(p[cond,j])
# }
#re-order groups from time to time
if (i<nburn & i%%accept.output==0){
ind=order(theta,decreasing=T)
theta=theta[ind]
betas=betas[,ind]
jump1$betas=jump1$betas[,ind]
z1=rep(NA,length(z))
for (k in 1:ngroup){
cond=z==ind[k]
z1[cond]=k
}
z=z1
}
#adaptation MH algorithm
if (i<nburn & i%%accept.output==0){
k=print.adapt(accept1z=accept1,jump1z=jump1,accept.output=accept.output)
accept1=k$accept1
jump1=k$jump1
}
#store results
store.betas[i,]=betas
store.b[i]=b.gamma
store.llk[i]=sum(llk1)
store.theta[i,]=theta
z.estim=z
}
i=1
print(i)
#sample betas
tmp=sample.betas(betas=betas,xmat=xmat,ysoma=ysoma,jump=jump1$betas,
b.gamma=b.gamma,nparam=nparam,var.betas=var.betas,
seg.id=seg.id,ngroup=ngroup,nagg=nagg,z=z)
betas
jump1$betas
var.betas
nparam
betas.old=betas.new=betas
jump=jump1$betas
betas.prop=matrix(rnorm(nparam*ngroup,mean=betas,sd=jump),nparam,ngroup)
betas.prop
accept=matrix(0,nparam,ngroup)
for (i in 1:nparam){
betas.new=betas.old
betas.new[i,]=betas.prop[i,]
pold=get.llk(betas=betas.old,xmat=xmat,ysoma=ysoma,
b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg)
pnew=get.llk(betas=betas.new,xmat=xmat,ysoma=ysoma,
b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg)
#get priors
prior.old =dnorm(betas.old[i,] ,mean=0,sd=sqrt(var.betas[i]),log=T)
prior.prop=dnorm(betas.prop[i,],mean=0,sd=sqrt(var.betas[i]),log=T)
#sum the loglikel for the correct group
pold1=GetSomaLlkGroups(llk=pold, z=z-1, ngroups=ngroup)
pnew1=GetSomaLlkGroups(llk=pnew, z=z-1, ngroups=ngroup)
# pold1=pnew1=rep(NA,ngroup)
# for (j in 1:ngroup){
#   cond=z==j
#   pold1[j]=sum(pold[cond,j])
#   pnew1[j]=sum(pnew[cond,j])
# }
#MH algorithm
pold2=pold1+prior.old
pnew2=pnew1+prior.prop
pthresh=exp(pnew2-pold2)
cond=runif(ngroup)<pthresh
betas.old[i,cond]=betas.new[i,cond]
accept[i,cond]=1
}
nparam
i=1
betas.new=betas.old
betas.new[i,]=betas.prop[i,]
pold=get.llk(betas=betas.old,xmat=xmat,ysoma=ysoma,
b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg)
pnew=get.llk(betas=betas.new,xmat=xmat,ysoma=ysoma,
b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg)
#get priors
prior.old =dnorm(betas.old[i,] ,mean=0,sd=sqrt(var.betas[i]),log=T)
prior.prop=dnorm(betas.prop[i,],mean=0,sd=sqrt(var.betas[i]),log=T)
#sum the loglikel for the correct group
pold1=GetSomaLlkGroups(llk=pold, z=z-1, ngroups=ngroup)
ysoma
pold1
pnew1
exp(sum(pnew1)-sum(pold1))
ysoma
ysoma/60
ysoma<- ysoma/60
var.betas=c(100,rep(1,ncol(xmat)-1))
mod.res=gibbs_resist(ysoma=ysoma,xmat=xmat,seg.id=seg.id,ngroup=ngroup,
ngibbs=ngibbs,nburn=nburn,var.betas=var.betas,
gamma1=gamma1)
